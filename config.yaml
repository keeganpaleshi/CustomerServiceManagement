openai:
  api_key_env: OPENAI_API_KEY        # name of env var or you can inline a key (not recommended)
  classify_model: "gpt-5-nano"       # Fast, cheap model optimized for classification
  draft_model:    "gpt-5"            # Full model for high-quality email drafting
  # Maximum tokens allowed in the draft generation call
  draft_max_tokens: 16384
  # System prompt used when drafting replies. Modify to change tone or style.
  draft_system_message: |
    Context: This is a business email for Cruising Solutions. You are replying
    to customers who have concerns or questions â€” some about orders they've
    placed, others about products they're considering purchasing. You should
    reply in the name of David, lead Customer Service Member, with the phone
    number 843-222-3660.

    Style Guidelines:

        Write in an email format.
        Be kind, courteous, and polite.
        Recognize any urgency in the customer's message.
        Provide helpful, succinct responses (most customers appreciate concise
        emails).
        Avoid giving specific dates or times when you will follow up (e.g., no
        "today," "tomorrow," or exact deadlines). Instead, use phrases such as:
            "as soon as possible"
            "at your earliest convenience"
        Occasionally use nautical terms, as most customers are sailors.
        If you don't have an answer to their question immediately, let them
        know you're checking into it and will respond once you have the
        information.
  # Maximum tokens for the classification model
  # Modern reasoning models benefit from higher limits for structured JSON responses
  classify_max_tokens: 512
  # Optional: Reasoning effort for draft generation (for reasoning models: o1, o3, gpt-5 series)
  # Supported values: none, minimal, low, medium, high, xhigh
  # Leave commented for default behavior (medium for most models, none for gpt-5.1+)
  # draft_reasoning_effort: "medium"
  # Optional: Reasoning effort for email classification (for reasoning models)
  # For gpt-5-nano, "low" reasoning significantly improves classification accuracy
  classify_reasoning_effort: "low"
  # Timeout (seconds) for OpenAI API requests
  # Reasoning models may require additional time for complex requests
  timeout: 60
  # Rate limiter for OpenAI calls (set max_requests or window_seconds to 0 to disable)
  rate_limit:
    max_requests: 60
    window_seconds: 60
  # Budget limits for OpenAI API costs (set to 0 to disable)
  budget:
    daily_usd: 10.0      # Maximum USD to spend per day (0 = unlimited)
    monthly_usd: 200.0   # Maximum USD to spend per month (0 = unlimited)
  # Pricing per 1M tokens (update when OpenAI changes prices)
  # Last updated: 2026-01 - check https://openai.com/api/pricing for current rates
  # Note: Reasoning models (o1, o3, gpt-5 series) support reasoning_effort parameter
  # Cached input pricing is 90% off for tokens used within previous few minutes
  pricing:
    # GPT-5.2 family - Latest flagship models (Dec 2025)
    gpt-5.2:
      input: 0.00175      # $1.75 per 1M input tokens
      output: 0.014       # $14.00 per 1M output tokens
      cached_input: 0.000175  # $0.175 per 1M cached tokens (90% discount)
    gpt-5.2-pro:
      input: 0.003        # $3.00 per 1M input tokens
      output: 0.024       # $24.00 per 1M output tokens
      cached_input: 0.0003
    # GPT-5 family - Previous generation
    gpt-5:
      input: 0.00125      # $1.25 per 1M input tokens
      output: 0.01        # $10.00 per 1M output tokens
      cached_input: 0.000125
    gpt-5-mini:
      input: 0.00025      # $0.25 per 1M input tokens
      output: 0.002       # $2.00 per 1M output tokens
      cached_input: 0.000025
    gpt-5-nano:
      input: 0.00005      # $0.05 per 1M input tokens
      output: 0.0004      # $0.40 per 1M output tokens
      cached_input: 0.000005
    gpt-5.1:
      input: 0.0015       # $1.50 per 1M input tokens
      output: 0.012       # $12.00 per 1M output tokens
      cached_input: 0.00015
    gpt-5.1-mini:
      input: 0.0003       # $0.30 per 1M input tokens
      output: 0.0024      # $2.40 per 1M output tokens
      cached_input: 0.00003
    # GPT-4.1 family - Reliable production models
    gpt-4.1:
      input: 0.002        # $2.00 per 1M input tokens
      output: 0.008       # $8.00 per 1M output tokens
    gpt-4.1-mini:
      input: 0.0004       # $0.40 per 1M input tokens
      output: 0.0016      # $1.60 per 1M output tokens
    # GPT-4o family - Previous flagship
    gpt-4o:
      input: 0.0025       # $2.50 per 1M input tokens
      output: 0.01        # $10.00 per 1M output tokens
    gpt-4o-mini:
      input: 0.00015      # $0.15 per 1M input tokens
      output: 0.0006      # $0.60 per 1M output tokens
    # o3 family - Reasoning models with reasoning_effort parameter support
    # Note: Reasoning tokens are hidden but billed as output tokens
    o3:
      input: 0.01         # $10.00 per 1M input tokens
      output: 0.04        # $40.00 per 1M output tokens
      cached_input: 0.0025  # $2.50 per 1M cached tokens
    o3-mini:
      input: 0.002        # $2.00 per 1M input tokens
      output: 0.008       # $8.00 per 1M output tokens
      cached_input: 0.0005
    # o1 family - Previous generation reasoning models
    o1:
      input: 0.015        # $15.00 per 1M input tokens
      output: 0.06        # $60.00 per 1M output tokens
    o1-mini:
      input: 0.003        # $3.00 per 1M input tokens
      output: 0.012       # $12.00 per 1M output tokens
    # Legacy models (maintained for compatibility)
    gpt-4:
      input: 0.03         # $30.00 per 1M input tokens
      output: 0.06        # $60.00 per 1M output tokens
    gpt-3.5-turbo:
      input: 0.001        # $1.00 per 1M input tokens
      output: 0.002       # $2.00 per 1M output tokens
    # Default pricing for unknown models (uses gpt-5.2 rates)
    default:
      input: 0.00175
      output: 0.014
  # Fallback email signature when OpenAI API fails or is rate limited
  fallback_signature: |
    Best,
    David
    Cruising Solutions Customer Support

thresholds:
  critic_threshold: 8.0
  max_retries:      2

limits:
  # Maximum number of drafts created in a single run
  max_drafts: 100
  # Maximum number of messages to process in a single run
  max_messages_per_run: 100

ticket:
  system:         "freescout"        # or "helpscout", "freshdesk", etc.
  # REQUIRED: FreeScout URL - set via FREESCOUT_URL env var or here
  freescout_url:  ""                 # e.g., "https://your-freescout-instance.com"
  # REQUIRED: FreeScout API key - set via FREESCOUT_KEY env var or here
  freescout_key:  ""                 # API key from FreeScout settings
  # REQUIRED: Numeric FreeScout mailbox ID used when creating conversations
  mailbox_id:     null                # e.g., 1
  # Rate limiter for FreeScout API calls (set to 0 to disable)
  rate_limit:
    max_requests: 100               # Maximum requests per window
    window_seconds: 60              # Time window in seconds
  gmail_thread_field_id: null         # custom field ID to store the Gmail threadId (optional)
  gmail_message_field_id: null        # custom field ID to store the Gmail messageId (optional)
  sqlite_path: "./csm.sqlite"        # durable store for processed messages and thread mapping
  webhook_enabled: false            # set true to use webhook ingestion (polling is disabled when enabled)
  webhook_secret: ""                 # shared secret for validating webhook requests
  poll_interval: 300                 # seconds between FreeScout polls when --poll-freescout is enabled
  actions:
    update_priority: true           # automatically set priority based on AI classification
    priority_high_threshold: 8      # importance score (1-10) that counts as high priority
    assign_to_user_id: null         # FreeScout user ID to assign tickets to (null = no assignment)
    apply_tags: true                # tag conversations with the detected type/importance
    custom_fields:
      type_field_id: null           # FreeScout custom field ID used to store "lead"/"customer"/"other"
      importance_field_id: null     # FreeScout custom field ID used to store the numeric importance
    post_internal_notes: true       # add an internal note summarizing the classification
    post_suggested_reply: true      # add an internal note containing a suggested AI reply
  followup:
    hours_without_reply: 24         # minimum hours since last customer message
    required_tags: []               # tags that must be present to qualify
    excluded_tags: ["followup-ready"] # tags that disqualify a conversation
    required_states: []             # optional FreeScout states/statuses to include
    followup_tag: "followup-ready"  # tag applied after drafting a follow-up
    limit: 100                      # maximum conversations to inspect per run
    dry_run: false                  # if true, log only
    list_params: {}                 # optional raw query params for /api/conversations
    p0_tags: ["p0"]                 # tags that mark a conversation as P0
    notify:
      slack_webhook_url: ""         # set to enable Slack notifications for P0 follow-ups (or use SLACK_WEBHOOK_URL env var)
      email:
        # SMTP settings can be overridden via environment variables:
        # SMTP_HOST, SMTP_PORT, SMTP_USERNAME, SMTP_PASSWORD, SMTP_FROM, SMTP_TO
        smtp_host: ""               # set to enable email notifications for P0 follow-ups (or use SMTP_HOST env var)
        smtp_port: 587              # override with SMTP_PORT env var
        smtp_username: ""           # override with SMTP_USERNAME env var
        smtp_password: ""           # override with SMTP_PASSWORD env var (recommended for security)
        from: ""                    # override with SMTP_FROM env var
        to: ""                      # override with SMTP_TO env var
        use_tls: true
        use_ssl: false
        timeout: 30             # SMTP connection timeout in seconds

gmail:
  scopes:
    - "https://www.googleapis.com/auth/gmail.modify"
  client_secret_file: "client_secret.json"
  token_file:         "token.json"
  # Set to true to force console-based OAuth (paste auth code) instead of opening a browser
  use_console_oauth:  false
  # Default Gmail search query
  query: "is:unread"

http:
  # Timeout (seconds) for external HTTP requests
  timeout: 15

# Webhook server configuration
webhook:
  # Directory for webhook payload logs (relative or absolute path)
  # Default: ./logs/webhooks
  log_dir: ""
  # Maximum age of webhook logs in days (older files are deleted)
  max_age_days: 30
  # Maximum number of webhook log files to keep
  max_files: 10000
  # Security settings for webhook validation
  security:
    # Maximum allowed time difference between webhook timestamp and server time (seconds)
    # Webhooks outside this window will be rejected to prevent replay attacks
    max_timestamp_skew_seconds: 300  # 5 minutes
    # Maximum number of nonces to cache for replay attack prevention
    nonce_cache_size: 10000
    # Time-to-live for nonce cache entries (seconds)
    nonce_cache_ttl_seconds: 600  # 10 minutes
